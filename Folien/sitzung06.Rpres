Statistik für Sprachwissenschaftler
========================================================
author: Phillip M . Alday
date: 2014-05-05   
autosize: false

```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE,prompt=TRUE)
library(knitcitations)
library(ggplot2)
library(reshape2)
```


Aufwachen und sich errinnern!
====================================
type: section


Bisher
========
- Häufigkeitsverteilungen und deren Kernwerte
  - Maße der Zentralen Tendenz 
  - Maße der Dispersion
- Visualsierung von Verteilungen
  - als Häufigkeit
  - als Dichte
  
Heute
=====
- Von Häufigkeitsverteilung zu Wahrscheinlichkeitsverteilungen
- Standardisierung von Verteilungen
- Einige wichtige Verteilungen
- (Population vs. Stichprobe)

Morgen
======
- Anwendung der Verteilungen: Inferenzstatistik
- Fehlerarten
- $p$-Werte
- evtl. Frequentism vs. Bayesianism

Daten für heute und morgen
============================
```{r, eval=FALSE}
rtdata <- read.table("Data/priming_rt.tab",header = T)
```
```{r, echo=FALSE}
# the path in the previous block isn't correct, so run this one
rtdata <- read.table(normalizePath("../Data/priming_rt.tab"),header = T)
```

```{r}
rtdata$subj <- as.factor(rtdata$subj)
summary(rtdata)
```
*Daten (c) Lisa Schaufler -- danke!* 

Vergleichbarkeit
==================
incremental: true
- Ist die RT von VP 1 (`r rtdata["1","RT"]`ms) schnell?
- Das hängt vom Referenzrahmen bzw. Vergleichsbasis ab:
  - Haben alle anderen Probanden eine RT von `r rtdata["1","RT"]/2`ms, ist `r rtdata["1","RT"]`ms langsam.
  - Bei einem Mittelwert von `r 0.9*rtdata["1","RT"]`ms hingegen wäre er tendenziell gut.
  
  
Standardwerte (z-Werte)
==========================
- Zentrierung
  - Relativierung am Mittelwert der Verteilung
  - $x_i - \bar{x}$
  - Zentrierung von allen Werten $\rightarrow$ zentrierte Verteilung mit $\bar{x} = 0$
- Standardisierung
  - Relativierung an der Standardabweichung der Verteilung
  - $x_i / s$

Standardwerte (z-Werte)
==========================
- $z$-Standardisierung ($z$-Transformation)
  - Zentrierung + Standardisierung
  - $z = (x_i - \bar{x}) / s$
  - $z$-Transformierung von allen Werten $\rightarrow$ standardisierte Verteilung mit $\bar{z} = 0, s_z = 1$



Beispiel (z-Werte)
====================
- Zentrieren:
```{r}
rt.zentriert <- rtdata$RT - mean(rtdata$RT)
head(rt.zentriert,n=4)
```
- $z$-Transformation
```{r}
rt.z <- (rtdata$RT - mean(rtdata$RT)) / sd(rtdata$RT)
head(rt.z,n=4)
```

Beispiel (z-Werte)
====================
- `scale(x, center=TRUE,scale = TRUE)`
```{r}
rt.z2 <- scale(rtdata$RT)
rt.z2[1:4]
```
- **OBACHT** bei `center=F,scale=T` entspricht der Skalierungsparameter nicht mehr der Standardabweichung.

Wahrscheinlichkeitsverteilungen
=================================
type:section

Von der Häufigkeitsverteilung zur Gesetzmäßigkeit
==================================================
- Bis jetzt: Beschreibung von Merkmalen und ihrer Ausprägung innerhalb einer Sammlung von Beobachtungen (*Stichprobe*)
- Noch nicht: ob sich dahinter allgemeinere Gesetzmäßigkeit verbergen

Beispiel: Effektivität von Gedächtnistraining
===============================================
- Ein Gedächtnisforscher preist eine Methode an, mit der man
angeblich die Gedächtnisleistung steigern kann.
- Ein Kollege bezweifelt die Effektivität der Methode.
- Sie einigen sich auf einen empirische Test ...
- Gedächtnistest (fiktiv!), der die Gedächtnisleistung mit
unendlicher Genauigkeit ermitteln kann
  - Testwerte ($X$): stetige (*continuous*) Variable
  - Populationsverteilung der Testwerte:$\mu = 50, \sigma^2 = 100$ 
  
*aus Eid et al. (2010, Kapitel 8)*

Exkurs: Population vs. Stichprobe
===================================
incremental:true
- Wir wollen Aussagen über Populationen machen, also generelle Unterschiede finden, aber ...
- es ist oft nicht möglich, Daten zur ganzen Population zu erheben, daher ...
- veruschen wir  durch eine Stichprobe eine Schätzung auf die Populationswerte zu machen

Exkurs: Population vs. Stichprobe
===================================
- Population
- griechisch
- $\mu$
- $\sigma^2_x$

***

- Stichprobe
- latenisch
- $\bar{x}$
- $s^2_x$


Beispiel: Effektivität von Gedächtnistraining
===============================================
incremental:true
- Eine studentische Hilfskraft wählt aus der Population zufällig eine
Gruppe (Stichprobe) aus und unterzieht sie dem Training.
- Befund: Mittelwert in der Gruppe der trainierten Personen
  - $\bar{x} = 58$
  - d.h. der Wert ist größer als der Populationsmittelwert $\mu = 50$
- Zeigt dies, dass der Test effektiv ist und die Gedächtnisleistung
steigert?

*aus Eid et al. (2010, Kapitel 8)*

Beispiel: Effektivität von Gedächtnistraining
===============================================
- Zeigt der höhere Stichprobenmittelwert bei trainierten Personen im
Vergleich zum Populationsmittelwert bei untrainierten Personen,
dass der Test effektiv ist und die Gedächtnisleistung steigert?
- Das Problem dabei:
  - Die Populationsvarianz $\sigma^2 = 100$ zeigt, dass sich Personen in
ihrer Gedächtnisleistung unterscheiden
  - Zieht man zufällig eine Person, wird sich deren Testwert
wahrscheinlich vom Populationsmittelwert unterscheiden,
ebenso der Mittelwert einer Stichprobe ...


*aus Eid et al. (2010, Kapitel 8)*


Beispiel: Effektivität von Gedächtnistraining
===============================================
- Wie kann man nun feststellen, ob der Unterschied zufällig zustande
gekommen ist oder nicht?


*aus Eid et al. (2010, Kapitel 8)*


Zufall
===============
type:alert
Wie wahrscheinlich ist das beobachtete Ergebnis?

Zufallsvariablen
====================
- **Variablen:** veränderliche Größen, die Objekte beschreiben und hinsichtlich
derer sich Objekte unterscheiden
- **Zufallsvariablen:** Eine Zufallsvariable ist eine Funktion, die den Ergebnissen eines Zufallsexperimentes (d. h. Elementarereignissen oder Ereignissen) reelle Zahlen zuordnet. (Bortz & Schuster, 2011: 61)
- Was ist ein Zufallsexperiment?

Zufallsvariablen
====================
- **Zufallsexperiment:** ein Vorgang, der nach einer bestimmten Vorschrift
beliebig häufig durchgeführt werden kann und dessen Ausgang nur
vom Zufall abhängt
  - **Beispiele:** Würfeln, Münzwurf, Messen einer Reaktionszeit / Fehlerrate ...
  - **Elementarereignis:** mögliches Ergebnis des Experiments (z.B. Würfeln einer 1)
- **Ereignis:** Teilmenge von Elementarereignissen (z.B. alle geraden Augenzahlen beim Würfeln)

Beispiel: Münzwurf
===================
incremental:true
Wie wahrscheinlich ist es, beim fünfmaligen Münzwurf das Ereignis $A =
{(K,Z,K,K,Z)}$ zu erhalten?

dieses Ereignis kommt im Ereignisraum nur einmal vor, daher: 

P(A) = 1/32 = `r 1/32` = `r 1/32 * 100`%

Beispiel: Münzwurf
===================
incremental:true
Wie wahrscheinlich ist es, beim fünfmaligen Münzwurf genau dreimal Kopf zu erhalten?

alle Ereignisse mit dreimal Kopf $\binom{5}{3} = 10$: 

P(A) = 10/32 = `r 10/32` = `r 10/32 * 100`%

Beispiel: Münzwurf
===================
incremental:true
Wie wahrscheinlich ist es, beim fünfmaligen Münzwurf mindestens viermal Zahl zu erhalten?
  
alle Ereignisse mit vier- oder fünfmal Zahl $\binom{5}{4} + \binom{5}{5}= 6$: 

P(A) = 6/32 = `r 6 / 32`

Warum ist das für uns relevant?
======================================
> Die Größe eines $\bar{x}$-Wertes hängt von der zufälligen Zusammensetzung der Stichprobe ab und stellt damit eine Realisierung einer Zufallsvariablen dar. (Bortz & Schuster, 2010: 61)

Für unsere weiteren Überlegungen müssen wir berücksichtigen, mit welcher Wahrscheinlichkeit die unterschiedlichen Werte einer Zufallsvariablen auftreten.

Dazu: **Wahrscheinlichkeitsverteilungen.**


Wahrscheinlichkeitsverteilungen
==================================
Wir müssen unterscheiden zwischen
  - diskreten Zufallsvariablen: endliche Anzahl der Ergebnisse (oder abzählbar unendlich), z.B. Münzwurf, Würfeln ...
  - stetigen Zufallsvariablen: unendliche Anzahl der Ergebnisse, z.B. Reaktionszeit


... bei diskreten Zufallsvariablen
====================================================================
Wahrscheinlichsfunktion für die Augensumme beim einmaligen Werfen zweier Würfel:
```{r, echo=FALSE}
df <-expand.grid(left=1:6,right=1:6)
df$sum <- df$left + df$right
dist <- data.frame(xtabs(~df$sum))
dist$Freq <- dist$Freq / sum(dist$Freq)
qplot(x=df.sum,y=Freq,data=dist,geom="bar",xlab="x",ylab="P(x)",stat="identity")
```

... bei diskreten Zufallsvariablen
====================================================================
Wahrscheinlichsfunktion für die Augensumme beim einmaligen Werfen zweier Würfel

- Wahrscheinlichkeit für 8:
  - $P(2 \cap 6) = 1 / 6 \cdot 1 / 6 = 1 / 36$
  - $P(3 \cap 5) = 1 / 6 \cdot 1 / 6 = 1 / 36$
  - $P(4 \cap 4) = 1 / 6 \cdot 1 / 6 = 1 / 36$
  - $P(5 \cap 3) = 1 / 6 \cdot 1 / 6 = 1 / 36$
  - $P(6 \cap 2) = 1 / 6 \cdot 1 / 6 = 1 / 36$
  - $P(8) = 5 / 36$ = `r 5 / 36`

... bei diskreten Zufallsvariablen
====================================================================
Wahrscheinlichsfunktion für die Augensumme beim einmaligen Werfen zweier Würfel

- Wahrscheinlichkeit für den Bereich 6--8?
  - $5/36 + 6 / 36 + 5 / 36 = 16 / 36)$
  
... bei diskreten Zufallsvariablen
====================================================================
Erwartungswert ($E(x)$ oder $\mu$) und Varianz ($\sigma^2$ oder $\text{Var}(X)$) einer diskreten Zufallsverteilung kennzeichnen die theoretische Verteilung der Zufallsvariable 

- $\mu = \sum_{i=1}^n x_i \cdot P(x_i)$
- $\sigma^2 = \sum_{i=1}^n \left(x_i - \mu\right)^2 \cdot P(x_i)$

... bei diskreten Zufallsvariablen
====================================================================
```{r, echo=TRUE}
df <-expand.grid(left=1:6,right=1:6)
df$sum <- df$left + df$right
head(df,n=3)
tail(df,n=3)
```

... bei diskreten Zufallsvariablen
====================================================================
```{r, echo=TRUE}
counts <- data.frame(xtabs(~df$sum))
names(counts) <- c("x","freq")
counts$x <- as.numeric(counts$x)
counts$p <- counts$freq / sum(counts$freq)
wuerfel <- counts$p * counts$x
wuerfel
```

... bei diskreten Zufallsvariablen
====================================================================
```{r, echo=TRUE}
erwartungswert <- sum(wuerfel)
erwartungswert
```

... bei diskreten Zufallsvariablen
====================================================================
```{r}
wuerfel.varianz <- sum( (counts$x - erwartungswert)^2 *counts$p )
wuerfel.varianz
```

Verteilungsfunktion bei diskreten Zufallsvariablen
====================================================================
- **(kumlative) Verteilungsfunktion:** gibt die kumulierte Wahrscheinlichkeit für einen Wert an
- $F(x_i) = P(x \leq x_i)$
- engl. *cumulative distribution function*, CDF
- Berechnung: $$F(x_i) = \sum_{j\leq i} P(x_j)$$

Verteilungsfunktion ...
====================================================================
left:60%
```{r eval=FALSE}
qplot(x=x,
      y=cumsum(p),
      data=counts,
      geom="bar",
      stat="identity",
      xlab="x",
      ylab="P(x' < x)")
```
***
```{r echo=FALSE}
qplot(x=x,
      y=cumsum(p),
      data=counts,
      geom="bar",
      stat="identity",
      xlab="x",ylab="P(x' < x)")
```

Wahrscheinlichkeitsverteilungen bei stetigen Zufallsvariablen
===============================================================
- Beispiel: Körpergewicht gemessen mit einer unendlich genauen Waage
- Zwischen zwei Werten liegen unendlich viele Zwischenwerte; daher ist die Wahrscheinlichkeit für einen bestimmten Wert $\rightarrow$ 0
- Daher: Wahrscheinlichkeiten für Werteintervalle (z.B. $P(60\leq X \leq 70)$)

... bei stetigen Zufallsvariablen
===============================================================
- Dichtefunktion:
  - Annahme: Kategoriebreite $d$ (manchmal $\Delta{}x$) wird immer kleiner und geht gegen
0 ($d \rightarrow 0$), d.h. es gibt unendlich viele Kategorien ($k \rightarrow \infty$)
- Fläche unter der Dichte = Wahrscheinlichkeit
- Fläche unter der Verteilung = 1: $$\int_{-\infty}^{\infty}P(x) dx = 1$$

... bei stetigen Zufallsvariablen
===============================================================
```{r, echo=FALSE}
set.seed(42)
x <- seq(-3,3,length.out=1000)
y <- dnorm(x)
ndata <- data.frame(x,y)
nplot <- qplot(x=x,y=y,data=ndata,
      geom="line",
      xlab="x",ylab="P(x)")
nplot
```
***
```{r,echo=FALSE}
nplot + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
data=subset(ndata, x > -1 & x < 0),
fill="red",alpha=0.5)
```

CDF bei stetigen Zufallsvariablen
=====================================
- Die Verteilungsfunktion gibt für einen Wert an, wie viel Prozent der
Verteilung unter diesem Wert liegt.
- **Verteilungsperzentil:** Das Perzentil $x_p$ einer Verteilung ist der Wert, unter dem $p$-Prozent der Verteilung liegen. Mit anderen Worten, $x_p$ wird durch die Gleichung $P(x \leq x_p) = p$ definiert. (Bortz & Schuster, 2011: 69)
- Verteilungsfunktion: $$F(x_p) = P(x \leq x_p ) = \int_{-\infty}^{x_p}P(t) dt$$

CDF bei stetigen Zufallsvariablen
=====================================
- Verteilungsfunktion: $$F(x_p) = P(x \leq x_p ) = \int_{-\infty}^{x_p}P(t) dt$$
- Damit kann auch die Wahrscheinlichkeit für einen Wert größer als $x_p$ berechnet werden (*Komplementärwahrscheinlichkeit*): $P(x > x_p ) = 1 − P(x \leq x_p )$

CDF bei stetigen Zufallsvariablen
=====================================
```{r,echo=FALSE}
nplot
``` 
*** 
CDF bei stetigen Zufallsvariablen
=====================================
```{r,echo=FALSE}
nplot + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
data=subset(ndata, pnorm(x) <= 0.05),
fill="red",alpha=0.5)
``` 
***
- $P(x \leq x_p )$


CDF bei stetigen Zufallsvariablen
=====================================
```{r,echo=FALSE}
nplot + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
data=subset(ndata, pnorm(x) <= 0.05),
fill="red",alpha=0.5) + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
data=subset(ndata, pnorm(x) > 0.05),
fill="blue",alpha=0.5)
```
***
- $P(x \leq x_p )$
- $P(x > x_p )$ =  $1 - P(x \leq x_p )$


CDF bei stetigen Zufallsvariablen
=====================================
```{r,echo=FALSE}
nplot + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
data=subset(ndata, pnorm(x) <= 0.05),
fill="red",alpha=0.5)
```
***
5% (lower tail)


CDF bei stetigen Zufallsvariablen
=====================================
```{r, echo=FALSE}
nplot + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
  data=subset(ndata, pnorm(x,lower.tail=TRUE) <= 0.025),
  fill="red",alpha=0.5) + 
geom_ribbon(aes(x=x,ymin=0,ymax=y),
  data=subset(ndata, pnorm(x,lower.tail=FALSE) <= 0.025),
  fill="red",alpha=0.5)
```
***
5% (two-tailed) is 2.5% at each tail

Beispiel: Dichtefunktion bei Reaktionszeiten
=============================================
```{r}
plot(density(rtdata$RT))
``` 

Die Normalverteilung
=====================
- Wichtigste Verteilungsform (auch Gauß-Verteilung genannt, da sie von
dem Mathematiker Carl Friedrich Gauß (1777-1855) beschrieben wurde)
- Glockenförmiger Verlauf, symmetrisch und unimodal
- Nähert sich asymptotisch der Abzisse an, berührt sie jedoch an keiner Stelle (Werte nicht nach unten oder oben beschränkt)
- ca. 2/3 der Gesamtfläche zwischen den Wendepunkten (*inflection points*)


Die Normalverteilung
=====================
- Normalverteilungen sind charakterisiert durch:
  - den Erwartungswert ($\mu$)
  - die Streuung ($\sigma$)
- ist x normalverteilt: $X \sim{} N(\mu,\sigma^2)$
- Dichtefunktion: $$F(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$$


Normalverteilungen in R
=======================
* `plot(dnorm(...),type="l")` bzw. `qplot(dnorm(...))`
* `curve(dnorm(...))`
* `geom_density()` 

Normalverteilungen in R
=======================
* `pnorm()`: Verteilungsfunktion (*p* für *probability*)
* `qnorm()`: Quantilfunktion (Kehrfunktion von `pnorm()`)
* `dnorm()`: Dichtefunktion
* `rnorm()`: Zufallsvariabel (*r* für *random*, für Simulationen nützlich)

Beispiel: Intelligenztests (IQ)
================================
incremental: true
* $\mu = 100$, $\sigma=15$
* Wie ist die Wahrscheinlichkeit, dass jemand einen IQ von *genau* 140 hat?
```{r}
dnorm(140,sd=15,mean=100)
```

Beispiel: Intelligenztests (IQ)
================================
incremental: true
* Wie ist die Wahrscheinlichkeit, dass jemand einen IQ von 140 oder niedriger hat?
```{r}
pnorm(140,sd=15,mean=100)
```

Beispiel: Intelligenztests (IQ)
================================
incremental: true
* Wie ist die Wahrscheinlichkeit, dass jemand einen IQ über 140  hat?
```{r}
pnorm(140,sd=15,mean=100,lower.tail=FALSE)
1 - pnorm(140,sd=15,mean=100)
```

Beispiel: Intelligenztests (IQ)
================================
incremental: true
* Welcher IQ entspricht dem 99,99-Perzentil?
```{r}
qnorm(.9999,sd=15,mean=100)
```

Beispiel: Intelligenztests (IQ)
================================
* Welcher Anteil der Bevölkerung hat einen IQ zwischen 85 und 115?
```{r}
pnorm(115,sd=15,mean=100) - pnorm(85,sd=15,mean=100)
``` 

Beispiel: Intelligenztests (IQ)
================================
* Welcher Anteil der Bevölkerung hat einen IQ zwischen 85 und 115?

```{r,echo=FALSE}
iqdist <- data.frame(x=40:160, y=dnorm(40:160,sd=15,mean=100))
iqplot <- qplot(x=x, y=y, data=iqdist ,geom="density",stat="identity",xlab="IQ",ylab="Dichte")
iqplot.1sd <- iqplot + geom_ribbon(aes(x=x,ymax=y,ymin=0),data=subset(iqdist,x >= 85 & x < 115),alpha=0.5,fill="blue")
iqplot.1sd
``` 

Beispiel: Intelligenztests (IQ)
================================
* Zwischen 70 und 130? 
```{r, echo=TRUE}
pnorm(130,sd=15,mean=100) - pnorm(70,sd=15,mean=100)
``` 

Beispiel: Intelligenztests (IQ)
================================
* Zwischen 70 und 130? 

```{r,echo=FALSE}
iqplot.2sd <- iqplot.1sd + geom_ribbon(aes(x=x,ymax=y,ymin=0),data=subset(iqdist,x >= 70 & x < 130),alpha=0.5,fill="red")
iqplot.2sd
``` 

Hausaufgabe
============
Bis morgen, lesen Sie: 
- [wie Statistik oft misbraucht wird](http://www.cracked.com/article_20318_the-5-most-popular-ways-statistics-are-used-to-lie-to-you.html).
- [warum es in den letzten Jahren eine Krise in der Wissenschaft gibt](http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble) (und warum ich so fanatisch geworden bin).

Anhang: ein paar weitere wichtige Verteilungen
===============================================
type:section


Binomialverteilung
=====================
- diskrete Entsprechung der Normalverteilung
- Wahrschlichkeit für das interessierende Ereinis $\pi$ und die Anzahl der Durchgänge $n$: $X \sim{} B(n,\pi)$
- Bei $\pi = 0.5$: Wurf einer fairen Münze 
- R-Funktionen: `pbinom()`,`dbinom()`,`rbinom()`, s. auch `choose()`, `combn()`
```{r, echo=F}
qplot(x=0:20,y=dbinom(0:20,20,prob=0.5),geom="point",xlab="x",ylab="P(x)")
```

Pareto und Zipf
================
- mehr dazu später (mit Handout)

Poisson
========
- mehr dazu später (mit Handout)

Bibliography
=============
```{r, echo=FALSE,results='hide'}
```

```{r,results='asis',echo=FALSE}
bibliography()
```

